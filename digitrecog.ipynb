{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import utils\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras import datasets\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import History\n",
    "\n",
    "from keras import losses\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.random.seed(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "x_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x1440 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(10,20))\n",
    "for i in range (10):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap =plt.cm.binary)\n",
    "    plt.xlabel(y_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2606f091f40>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "five = x_train[0].copy()\n",
    "plt.imshow(five, cmap=plt.cm.binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      " 225 172 253 242 195  64   0   0   0   0]\n",
      "[  0   0   0   0   0   0   0   0 255 255 255 255 255 255 255 255 255 255\n",
      " 255 255 255 255 255 255   0   0   0   0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x260000fa7f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Thresholding\n",
    "print(five[6])\n",
    "five[five>0]=255\n",
    "print(five[6])\n",
    "\n",
    "plt.imshow(five,cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 60000 train samples\n",
      "we have 10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print(f'we have {x_train.shape[0]} train samples')\n",
    "print(f'we have {x_test.shape[0]} test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "x_train,x_test = x_train/255.0 ,x_test /255.0#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data into 1-D vecor\n",
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)\n",
    "num_classes =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "epochs= 60\n",
    "learing_rate = 0.1\n",
    "decay_rate = learing_rate / epochs\n",
    "momentum =0.8\n",
    "sgd=SGD(lr=learing_rate , momentum=momentum,decay=decay_rate, nesterov= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "input_dim =x_train.shape[1]\n",
    "\n",
    "lr_model = Sequential()\n",
    "lr_model.add(Dense(64,activation= tf.nn.relu,\n",
    "kernel_initializer='uniform',input_dim= input_dim))\n",
    "\n",
    "lr_model.add(Dropout(0.1))\n",
    "lr_model.add(Dense(64,activation= tf.nn.relu))\n",
    "lr_model.add(Dense(num_classes,kernel_initializer='uniform',activation=tf.nn.softmax))\n",
    "\n",
    "# compile the model\n",
    "lr_model.compile(loss='categorical_crossentropy',\n",
    "optimizer=sgd,\n",
    "metrics= ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "8572/8572 [==============================] - 15s 1ms/step - loss: 0.3769 - acc: 0.8857 - val_loss: 0.1864 - val_acc: 0.9433\n",
      "Epoch 2/60\n",
      "8572/8572 [==============================] - 11s 1ms/step - loss: 0.2163 - acc: 0.9336 - val_loss: 0.1615 - val_acc: 0.9506\n",
      "Epoch 3/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1929 - acc: 0.9414 - val_loss: 0.1479 - val_acc: 0.9548\n",
      "Epoch 4/60\n",
      "8572/8572 [==============================] - 11s 1ms/step - loss: 0.1815 - acc: 0.9445 - val_loss: 0.1440 - val_acc: 0.9570\n",
      "Epoch 5/60\n",
      "8572/8572 [==============================] - 11s 1ms/step - loss: 0.1730 - acc: 0.9468 - val_loss: 0.1404 - val_acc: 0.9571\n",
      "Epoch 6/60\n",
      "8572/8572 [==============================] - 11s 1ms/step - loss: 0.1694 - acc: 0.9487 - val_loss: 0.1361 - val_acc: 0.9591\n",
      "Epoch 7/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1625 - acc: 0.9495 - val_loss: 0.1347 - val_acc: 0.9592\n",
      "Epoch 8/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1625 - acc: 0.9501 - val_loss: 0.1322 - val_acc: 0.9606\n",
      "Epoch 9/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1553 - acc: 0.9517 - val_loss: 0.1311 - val_acc: 0.9609\n",
      "Epoch 10/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1541 - acc: 0.9524 - val_loss: 0.1278 - val_acc: 0.9619\n",
      "Epoch 11/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1509 - acc: 0.9530 - val_loss: 0.1284 - val_acc: 0.9617\n",
      "Epoch 12/60\n",
      "8572/8572 [==============================] - 13s 2ms/step - loss: 0.1493 - acc: 0.9545 - val_loss: 0.1267 - val_acc: 0.9619\n",
      "Epoch 13/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1491 - acc: 0.9546 - val_loss: 0.1267 - val_acc: 0.9622\n",
      "Epoch 14/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1478 - acc: 0.9546 - val_loss: 0.1260 - val_acc: 0.9626\n",
      "Epoch 15/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1454 - acc: 0.9548 - val_loss: 0.1246 - val_acc: 0.9634\n",
      "Epoch 16/60\n",
      "8572/8572 [==============================] - 13s 2ms/step - loss: 0.1446 - acc: 0.9550 - val_loss: 0.1242 - val_acc: 0.9627\n",
      "Epoch 17/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1435 - acc: 0.9566 - val_loss: 0.1241 - val_acc: 0.9628\n",
      "Epoch 18/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1419 - acc: 0.9564 - val_loss: 0.1228 - val_acc: 0.9634\n",
      "Epoch 19/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1398 - acc: 0.9573 - val_loss: 0.1220 - val_acc: 0.9632\n",
      "Epoch 20/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1380 - acc: 0.9577 - val_loss: 0.1227 - val_acc: 0.9636\n",
      "Epoch 21/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1386 - acc: 0.9572 - val_loss: 0.1222 - val_acc: 0.9639\n",
      "Epoch 22/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1372 - acc: 0.9578 - val_loss: 0.1223 - val_acc: 0.9636\n",
      "Epoch 23/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1365 - acc: 0.9585 - val_loss: 0.1217 - val_acc: 0.9640\n",
      "Epoch 24/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1354 - acc: 0.9584 - val_loss: 0.1216 - val_acc: 0.9645\n",
      "Epoch 25/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1342 - acc: 0.9587 - val_loss: 0.1206 - val_acc: 0.9638\n",
      "Epoch 26/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1347 - acc: 0.9580 - val_loss: 0.1201 - val_acc: 0.9641\n",
      "Epoch 27/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1332 - acc: 0.9589 - val_loss: 0.1201 - val_acc: 0.9642\n",
      "Epoch 28/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1316 - acc: 0.9597 - val_loss: 0.1196 - val_acc: 0.9642\n",
      "Epoch 29/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1323 - acc: 0.9585 - val_loss: 0.1197 - val_acc: 0.9647\n",
      "Epoch 30/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1312 - acc: 0.9601 - val_loss: 0.1188 - val_acc: 0.9651\n",
      "Epoch 31/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1300 - acc: 0.9602 - val_loss: 0.1187 - val_acc: 0.9649\n",
      "Epoch 32/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1303 - acc: 0.9593 - val_loss: 0.1182 - val_acc: 0.9649\n",
      "Epoch 33/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1308 - acc: 0.9595 - val_loss: 0.1182 - val_acc: 0.9645\n",
      "Epoch 34/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1305 - acc: 0.9595 - val_loss: 0.1182 - val_acc: 0.9650\n",
      "Epoch 35/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1295 - acc: 0.9595 - val_loss: 0.1181 - val_acc: 0.9650\n",
      "Epoch 36/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1284 - acc: 0.9608 - val_loss: 0.1175 - val_acc: 0.9655\n",
      "Epoch 37/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1276 - acc: 0.9611 - val_loss: 0.1171 - val_acc: 0.9651\n",
      "Epoch 38/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1276 - acc: 0.9607 - val_loss: 0.1177 - val_acc: 0.9650\n",
      "Epoch 39/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1254 - acc: 0.9614 - val_loss: 0.1171 - val_acc: 0.9652\n",
      "Epoch 40/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1259 - acc: 0.9617 - val_loss: 0.1167 - val_acc: 0.9651\n",
      "Epoch 41/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1265 - acc: 0.9610 - val_loss: 0.1172 - val_acc: 0.9652\n",
      "Epoch 42/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1262 - acc: 0.9614 - val_loss: 0.1171 - val_acc: 0.9653\n",
      "Epoch 43/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1236 - acc: 0.9625 - val_loss: 0.1163 - val_acc: 0.9657\n",
      "Epoch 44/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1248 - acc: 0.9619 - val_loss: 0.1158 - val_acc: 0.9651\n",
      "Epoch 45/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1261 - acc: 0.9616 - val_loss: 0.1161 - val_acc: 0.9652\n",
      "Epoch 46/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1247 - acc: 0.9618 - val_loss: 0.1158 - val_acc: 0.9654\n",
      "Epoch 47/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1263 - acc: 0.9612 - val_loss: 0.1161 - val_acc: 0.9656\n",
      "Epoch 48/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1238 - acc: 0.9619 - val_loss: 0.1153 - val_acc: 0.9652\n",
      "Epoch 49/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1218 - acc: 0.9628 - val_loss: 0.1154 - val_acc: 0.9663\n",
      "Epoch 50/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1217 - acc: 0.9623 - val_loss: 0.1154 - val_acc: 0.9654\n",
      "Epoch 51/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1231 - acc: 0.9618 - val_loss: 0.1150 - val_acc: 0.9650\n",
      "Epoch 52/60\n",
      "8572/8572 [==============================] - 12s 1ms/step - loss: 0.1226 - acc: 0.9627 - val_loss: 0.1150 - val_acc: 0.9653\n",
      "Epoch 53/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1207 - acc: 0.9627 - val_loss: 0.1153 - val_acc: 0.9657\n",
      "Epoch 54/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1243 - acc: 0.9617 - val_loss: 0.1153 - val_acc: 0.9655\n",
      "Epoch 55/60\n",
      "8572/8572 [==============================] - 13s 2ms/step - loss: 0.1189 - acc: 0.9638 - val_loss: 0.1148 - val_acc: 0.9656\n",
      "Epoch 56/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1203 - acc: 0.9633 - val_loss: 0.1146 - val_acc: 0.9657\n",
      "Epoch 57/60\n",
      "8572/8572 [==============================] - 13s 2ms/step - loss: 0.1207 - acc: 0.9634 - val_loss: 0.1145 - val_acc: 0.9659\n",
      "Epoch 58/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1197 - acc: 0.9632 - val_loss: 0.1142 - val_acc: 0.9657\n",
      "Epoch 59/60\n",
      "8572/8572 [==============================] - 13s 1ms/step - loss: 0.1205 - acc: 0.9636 - val_loss: 0.1145 - val_acc: 0.9655\n",
      "Epoch 60/60\n",
      "8572/8572 [==============================] - 13s 2ms/step - loss: 0.1210 - acc: 0.9622 - val_loss: 0.1140 - val_acc: 0.9657\n",
      "CPU times: total: 20min 15s\n",
      "Wall time: 12min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Fit the model\n",
    "batch_size = int(input_dim/100)\n",
    "\n",
    "lr_model_history = lr_model.fit(x_train,y_train,batch_size= batch_size,epochs = epochs,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplot(1,1, figsize = (18,6))\n",
    "ax.plot(np.sqrt(lr_model_history.history['acc']),'r',label='train')\n",
    "ax.plot(np.sqrt(lr_model_history.history['val_acc']),'b',label='val')\n",
    "ax.set_xlabel(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "epochs= 30\n",
    "learing_rate = 0.1 # inital learning rate\n",
    "decay_rate = 0.1\n",
    "momentum =0.8\n",
    "sgd=SGD(lr=learing_rate , momentum=momentum,\n",
    "        decay=decay_rate, nesterov= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim =x_train.shape[1]\n",
    "num_classes =10\n",
    "batch_size =196\n",
    "\n",
    "# building the model\n",
    "\n",
    "exponential_decay_model = Sequential()\n",
    "exponential_decay_model.add(Dense(64,activation= tf.nn.relu,\n",
    "kernel_initializer='uniform',input_dim= input_dim))\n",
    "\n",
    "exponential_decay_model.add(Dropout(0.1))\n",
    "exponential_decay_model.add(Dense(64,kernel_initializer='uniform',activation= tf.nn.relu))\n",
    "exponential_decay_model.add(Dense(num_classes,kernel_initializer='uniform',activation=tf.nn.softmax))\n",
    "\n",
    "# compile the model\n",
    "exponential_decay_model.compile(loss='categorical_crossentropy',\n",
    "                                optimizer=sgd,\n",
    "                                metrics= ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the learinig rate change\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    lrate = learing_rate * np.exp(-decay_rate * epoch)\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 2.0411 - acc: 0.3922 - val_loss: 1.4945 - val_acc: 0.5786 - lr: 0.1000\n",
      "Epoch 2/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 1.2271 - acc: 0.6375 - val_loss: 0.9784 - val_acc: 0.7164 - lr: 0.0905\n",
      "Epoch 3/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.9611 - acc: 0.6990 - val_loss: 0.8400 - val_acc: 0.7518 - lr: 0.0819\n",
      "Epoch 4/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.8755 - acc: 0.7247 - val_loss: 0.7801 - val_acc: 0.7670 - lr: 0.0741\n",
      "Epoch 5/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.8310 - acc: 0.7363 - val_loss: 0.7461 - val_acc: 0.7763 - lr: 0.0670\n",
      "Epoch 6/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.8029 - acc: 0.7465 - val_loss: 0.7244 - val_acc: 0.7838 - lr: 0.0607\n",
      "Epoch 7/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7841 - acc: 0.7540 - val_loss: 0.7089 - val_acc: 0.7885 - lr: 0.0549\n",
      "Epoch 8/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7702 - acc: 0.7597 - val_loss: 0.6973 - val_acc: 0.7922 - lr: 0.0497\n",
      "Epoch 9/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7597 - acc: 0.7594 - val_loss: 0.6890 - val_acc: 0.7958 - lr: 0.0449\n",
      "Epoch 10/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7521 - acc: 0.7637 - val_loss: 0.6819 - val_acc: 0.7988 - lr: 0.0407\n",
      "Epoch 11/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7469 - acc: 0.7656 - val_loss: 0.6766 - val_acc: 0.8011 - lr: 0.0368\n",
      "Epoch 12/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7424 - acc: 0.7692 - val_loss: 0.6721 - val_acc: 0.8026 - lr: 0.0333\n",
      "Epoch 13/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7365 - acc: 0.7701 - val_loss: 0.6685 - val_acc: 0.8033 - lr: 0.0301\n",
      "Epoch 14/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7362 - acc: 0.7686 - val_loss: 0.6655 - val_acc: 0.8045 - lr: 0.0273\n",
      "Epoch 15/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7316 - acc: 0.7723 - val_loss: 0.6631 - val_acc: 0.8057 - lr: 0.0247\n",
      "Epoch 16/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7288 - acc: 0.7713 - val_loss: 0.6610 - val_acc: 0.8062 - lr: 0.0223\n",
      "Epoch 17/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7275 - acc: 0.7721 - val_loss: 0.6593 - val_acc: 0.8069 - lr: 0.0202\n",
      "Epoch 18/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7261 - acc: 0.7734 - val_loss: 0.6578 - val_acc: 0.8072 - lr: 0.0183\n",
      "Epoch 19/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7226 - acc: 0.7756 - val_loss: 0.6565 - val_acc: 0.8078 - lr: 0.0165\n",
      "Epoch 20/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7248 - acc: 0.7733 - val_loss: 0.6554 - val_acc: 0.8079 - lr: 0.0150\n",
      "Epoch 21/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7236 - acc: 0.7738 - val_loss: 0.6545 - val_acc: 0.8082 - lr: 0.0135\n",
      "Epoch 22/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7191 - acc: 0.7773 - val_loss: 0.6537 - val_acc: 0.8085 - lr: 0.0122\n",
      "Epoch 23/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7196 - acc: 0.7768 - val_loss: 0.6530 - val_acc: 0.8087 - lr: 0.0111\n",
      "Epoch 24/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7189 - acc: 0.7758 - val_loss: 0.6524 - val_acc: 0.8089 - lr: 0.0100\n",
      "Epoch 25/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7193 - acc: 0.7763 - val_loss: 0.6519 - val_acc: 0.8093 - lr: 0.0091\n",
      "Epoch 26/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7190 - acc: 0.7765 - val_loss: 0.6514 - val_acc: 0.8094 - lr: 0.0082\n",
      "Epoch 27/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7180 - acc: 0.7749 - val_loss: 0.6510 - val_acc: 0.8095 - lr: 0.0074\n",
      "Epoch 28/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7173 - acc: 0.7761 - val_loss: 0.6507 - val_acc: 0.8095 - lr: 0.0067\n",
      "Epoch 29/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7192 - acc: 0.7760 - val_loss: 0.6504 - val_acc: 0.8095 - lr: 0.0061\n",
      "Epoch 30/30\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 0.7169 - acc: 0.7776 - val_loss: 0.6502 - val_acc: 0.8095 - lr: 0.0055\n"
     ]
    }
   ],
   "source": [
    " # learning schedule callback\n",
    " loss_history = History()\n",
    " lr_rate = LearningRateScheduler(exp_decay)\n",
    " callbacks_list = [loss_history,lr_rate]\n",
    "\n",
    " # you invoke the learning rate scheduler during the .fit() phase\n",
    " exponential_decay_model_history = exponential_decay_model.fit(x_train,y_train,\n",
    "                                                                batch_size= batch_size,\n",
    "                                                                epochs=epochs,\n",
    "                                                                callbacks= callbacks_list,\n",
    "                                                                verbose= 1,\n",
    "                                                                validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check on the variable that can show me the learning rate decay \n",
    "exponential_decay_model_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using different loss functiton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim =x_train.shape[1]\n",
    "# building the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64,activation= tf.nn.relu,\n",
    "kernel_initializer='uniform',input_dim= input_dim))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64,kernel_initializer='uniform',activation= tf.nn.relu))\n",
    "model.add(Dense(num_classes,kernel_initializer='uniform',activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "rms = RMSprop(lr=0.001, rho=0.9 , epsilon= None, decay = 0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= rms,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2843 - acc: 0.9182 - val_loss: 0.2720 - val_acc: 0.9336\n",
      "Epoch 2/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2842 - acc: 0.9185 - val_loss: 0.2716 - val_acc: 0.9350\n",
      "Epoch 3/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2851 - acc: 0.9184 - val_loss: 0.2719 - val_acc: 0.9339\n",
      "Epoch 4/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2827 - acc: 0.9185 - val_loss: 0.2714 - val_acc: 0.9342\n",
      "Epoch 5/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2853 - acc: 0.9176 - val_loss: 0.2721 - val_acc: 0.9340\n",
      "Epoch 6/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2856 - acc: 0.9183 - val_loss: 0.2724 - val_acc: 0.9348\n",
      "Epoch 7/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2834 - acc: 0.9184 - val_loss: 0.2721 - val_acc: 0.9341\n",
      "Epoch 8/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2862 - acc: 0.9179 - val_loss: 0.2721 - val_acc: 0.9340\n",
      "Epoch 9/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2863 - acc: 0.9186 - val_loss: 0.2730 - val_acc: 0.9338\n",
      "Epoch 10/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2882 - acc: 0.9175 - val_loss: 0.2730 - val_acc: 0.9342\n",
      "Epoch 11/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2840 - acc: 0.9183 - val_loss: 0.2724 - val_acc: 0.9342\n",
      "Epoch 12/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2847 - acc: 0.9185 - val_loss: 0.2719 - val_acc: 0.9343\n",
      "Epoch 13/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2843 - acc: 0.9184 - val_loss: 0.2718 - val_acc: 0.9344\n",
      "Epoch 14/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2878 - acc: 0.9173 - val_loss: 0.2726 - val_acc: 0.9343\n",
      "Epoch 15/60\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.2843 - acc: 0.9184 - val_loss: 0.2726 - val_acc: 0.9336\n",
      "Epoch 16/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2862 - acc: 0.9177 - val_loss: 0.2728 - val_acc: 0.9341\n",
      "Epoch 17/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2850 - acc: 0.9181 - val_loss: 0.2728 - val_acc: 0.9337\n",
      "Epoch 18/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2847 - acc: 0.9186 - val_loss: 0.2720 - val_acc: 0.9335\n",
      "Epoch 19/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2869 - acc: 0.9171 - val_loss: 0.2727 - val_acc: 0.9343\n",
      "Epoch 20/60\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.2871 - acc: 0.9175 - val_loss: 0.2727 - val_acc: 0.9338\n",
      "Epoch 21/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2884 - acc: 0.9172 - val_loss: 0.2731 - val_acc: 0.9338\n",
      "Epoch 22/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2859 - acc: 0.9180 - val_loss: 0.2731 - val_acc: 0.9338\n",
      "Epoch 23/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2861 - acc: 0.9173 - val_loss: 0.2733 - val_acc: 0.9337\n",
      "Epoch 24/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2847 - acc: 0.9185 - val_loss: 0.2727 - val_acc: 0.9335\n",
      "Epoch 25/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2889 - acc: 0.9167 - val_loss: 0.2730 - val_acc: 0.9336\n",
      "Epoch 26/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2854 - acc: 0.9176 - val_loss: 0.2733 - val_acc: 0.9338\n",
      "Epoch 27/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2889 - acc: 0.9172 - val_loss: 0.2730 - val_acc: 0.9335\n",
      "Epoch 28/60\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.2850 - acc: 0.9184 - val_loss: 0.2731 - val_acc: 0.9341\n",
      "Epoch 29/60\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.2870 - acc: 0.9176 - val_loss: 0.2730 - val_acc: 0.9337\n",
      "Epoch 30/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2862 - acc: 0.9178 - val_loss: 0.2730 - val_acc: 0.9330\n",
      "Epoch 31/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2832 - acc: 0.9190 - val_loss: 0.2726 - val_acc: 0.9342\n",
      "Epoch 32/60\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.2839 - acc: 0.9187 - val_loss: 0.2730 - val_acc: 0.9339\n",
      "Epoch 33/60\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.2851 - acc: 0.9176 - val_loss: 0.2731 - val_acc: 0.9333\n",
      "Epoch 34/60\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.2843 - acc: 0.9183 - val_loss: 0.2728 - val_acc: 0.9340\n",
      "Epoch 35/60\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.2825 - acc: 0.9187 - val_loss: 0.2733 - val_acc: 0.9337\n",
      "Epoch 36/60\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.2825 - acc: 0.9194 - val_loss: 0.2732 - val_acc: 0.9335\n",
      "Epoch 37/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2898 - acc: 0.9166 - val_loss: 0.2733 - val_acc: 0.9335\n",
      "Epoch 38/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2853 - acc: 0.9186 - val_loss: 0.2735 - val_acc: 0.9333\n",
      "Epoch 39/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2822 - acc: 0.9184 - val_loss: 0.2731 - val_acc: 0.9342\n",
      "Epoch 40/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2884 - acc: 0.9169 - val_loss: 0.2733 - val_acc: 0.9342\n",
      "Epoch 41/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2901 - acc: 0.9168 - val_loss: 0.2742 - val_acc: 0.9336\n",
      "Epoch 42/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2860 - acc: 0.9180 - val_loss: 0.2738 - val_acc: 0.9338\n",
      "Epoch 43/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2853 - acc: 0.9185 - val_loss: 0.2732 - val_acc: 0.9335\n",
      "Epoch 44/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2878 - acc: 0.9172 - val_loss: 0.2734 - val_acc: 0.9337\n",
      "Epoch 45/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2898 - acc: 0.9169 - val_loss: 0.2736 - val_acc: 0.9334\n",
      "Epoch 46/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2837 - acc: 0.9190 - val_loss: 0.2731 - val_acc: 0.9337\n",
      "Epoch 47/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2860 - acc: 0.9179 - val_loss: 0.2730 - val_acc: 0.9336\n",
      "Epoch 48/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2873 - acc: 0.9178 - val_loss: 0.2739 - val_acc: 0.9336\n",
      "Epoch 49/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2847 - acc: 0.9183 - val_loss: 0.2733 - val_acc: 0.9339\n",
      "Epoch 50/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2838 - acc: 0.9190 - val_loss: 0.2732 - val_acc: 0.9338\n",
      "Epoch 51/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2865 - acc: 0.9172 - val_loss: 0.2736 - val_acc: 0.9333\n",
      "Epoch 52/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2889 - acc: 0.9171 - val_loss: 0.2734 - val_acc: 0.9335\n",
      "Epoch 53/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2833 - acc: 0.9182 - val_loss: 0.2739 - val_acc: 0.9337\n",
      "Epoch 54/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2879 - acc: 0.9182 - val_loss: 0.2738 - val_acc: 0.9341\n",
      "Epoch 55/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2872 - acc: 0.9171 - val_loss: 0.2737 - val_acc: 0.9347\n",
      "Epoch 56/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2805 - acc: 0.9197 - val_loss: 0.2732 - val_acc: 0.9340\n",
      "Epoch 57/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2804 - acc: 0.9190 - val_loss: 0.2723 - val_acc: 0.9337\n",
      "Epoch 58/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2875 - acc: 0.9178 - val_loss: 0.2736 - val_acc: 0.9334\n",
      "Epoch 59/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2815 - acc: 0.9190 - val_loss: 0.2728 - val_acc: 0.9338\n",
      "Epoch 60/60\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.2829 - acc: 0.9195 - val_loss: 0.2735 - val_acc: 0.9337\n"
     ]
    }
   ],
   "source": [
    "batch_size= input_dim\n",
    "epochs = 60\n",
    "\n",
    "model_history = model.fit(x_train,y_train,batch_size= batch_size,epochs=epochs,\n",
    "                          verbose= 1,validation_data=(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c72c2effabc4a11f904f0ad61bd52b3d78cffb4a1f9333e1cd3c945eafd87b8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('deeplearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
